{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1335d8e0-3d24-4cb7-a7c2-7459669546d0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Only tech_list should be maintained\n",
    "from datetime import datetime, timedelta\n",
    "yesterday = datetime.now() - timedelta(days=1)\n",
    "datekey = yesterday.strftime('%Y-%m-%d')\n",
    "\n",
    "# datekey = '2018-10-24'\n",
    "year, month, day = datekey.split('-')\n",
    "\n",
    "tech_list = [\n",
    "    ('gsm', '2g', '900'),\n",
    "    ('gsm', '2g', '1800'),\n",
    "    ('umts', '3g', '900'),\n",
    "    ('umts', '3g', '2100'),\n",
    "    \n",
    "    ('lte', '4g', '700'),\n",
    "    ('lte', '4g', '800'),\n",
    "    ('lte', '4g', '1800'),\n",
    "    ('lte', '4g', '2100'),\n",
    "    ('lte', '4g', '2600')\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b58b2f30-119b-453c-a5a5-a64d1c87a6ae",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, when, lit\n",
    "\n",
    "spark = SparkSession.builder.appName(\"MartechAssignment\").getOrCreate()\n",
    "\n",
    "\n",
    "df_tech_dimension = spark.createDataFrame([\n",
    "    (row[0], row[1], row[2], 'site_' + row[1] + '_cnt', 'frequency_band_' + row[0][0].upper() + row[2] ) for row in tech_list\n",
    "], [\"tech_type\", \"network_type\", \"frequency\", \"cell_cnt_value\", \"frequency_band_value\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3901c398-545f-4b0b-8556-c8b34f0284d8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_site = spark.read \\\n",
    "        .format(\"csv\") \\\n",
    "        .option(\"header\", \"true\") \\\n",
    "        .option(\"delimiter\", \";\") \\\n",
    "        .option(\"inferSchema\", \"true\") \\\n",
    "        .load(\"gs://martech-archive-data/Archive/site/year={year}/month={mon}/day={day}/*.csv\".format(year=year, mon=month, day=day))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0000bb37-302b-4f18-8b6d-02b2d030f72d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.types import StructType, StructField, StringType, IntegerType\n",
    "\n",
    "# Define the schema\n",
    "schema = StructType([\n",
    "    StructField(\"year\", IntegerType(), True),\n",
    "    StructField(\"month\", IntegerType(), True),\n",
    "    StructField(\"day\", IntegerType(), True),\n",
    "    StructField(\"cell_identity\", StringType(), True),\n",
    "    StructField(\"frequency_band\", StringType(), True),\n",
    "    StructField(\"site_id\", StringType(), True),\n",
    "    StructField(\"tech_type\", StringType(), True)\n",
    "])\n",
    "\n",
    "# Create an empty DataFrame with the defined schema\n",
    "df_data = spark.createDataFrame(spark.sparkContext.emptyRDD(), schema)\n",
    "\n",
    "\n",
    "# Merge all the data into a dataframe\n",
    "tech_types = set(item[0] for item in tech_list)\n",
    "for tech_type in tech_types:\n",
    "    path = \"gs://martech-archive-data/Archive/{type}/year={year}/month={mon}/day={day}/*.csv\".format(type=tech_type, year=year, mon=month, day=day)\n",
    "   \n",
    "    try:\n",
    "        df_tech_type = spark.read \\\n",
    "            .format(\"csv\") \\\n",
    "            .option(\"header\", \"true\") \\\n",
    "            .option(\"delimiter\", \";\") \\\n",
    "            .option(\"inferSchema\", \"true\") \\\n",
    "            .load(path)\n",
    "    except Exception as e:\n",
    "        continue\n",
    "\n",
    "    df_tech_type = df_tech_type.withColumn(tech_type, lit(tech_type))\n",
    "    df_data = df_data.union(df_tech_type)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1f7ff441-e590-4e05-8287-1841a4d743dc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_data.createOrReplaceTempView(\"martech_archive_data\")\n",
    "df_site.createOrReplaceTempView(\"martech_archive_site\")\n",
    "df_tech_dimension.createOrReplaceTempView(\"dim_tech_info\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2fde02c9-da7c-44ae-a137-a51bf3413a83",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Generate a dynamic sql to get the final cell result\n",
    "\n",
    "dynamic_tech_cell_cnt = [row[0] for row in df_tech_dimension.select('cell_cnt_value').distinct().collect()]\n",
    "\n",
    "\n",
    "# Dynamically generate the COALESCE and PIVOT clauses\n",
    "coalesce_clauses = \",\\n       \".join([f\"COALESCE(SUM(aa.{col}), 0) AS {col}\" for col in dynamic_tech_cell_cnt])\n",
    "pivot_values = \", \".join([f\"'{col}'\" for col in dynamic_tech_cell_cnt])\n",
    "\n",
    "dynamic_tech_cell_cnt_sql = f\"\"\"\n",
    "SELECT bb.year, bb.month, bb.day, bb.site_id,\n",
    "       {coalesce_clauses}\n",
    "FROM (\n",
    "  SELECT *\n",
    "  FROM (\n",
    "      SELECT year, month, day, tech_type, site_id,\n",
    "            COUNT(DISTINCT cell_identity) AS cell_cnt\n",
    "      FROM martech_archive_data\n",
    "      GROUP BY year, month, day, tech_type, site_id\n",
    "  )  a \n",
    "  JOIN (\n",
    "      SELECT tech_type, cell_cnt_value\n",
    "        FROM dim_tech_info\n",
    "       GROUP BY tech_type, cell_cnt_value\n",
    "  )  b ON a.tech_type = b.tech_type\n",
    "  PIVOT (\n",
    "    SUM(cell_cnt) AS cell_cnt\n",
    "    FOR cell_cnt_value IN ({pivot_values}) \n",
    "  )\n",
    ") aa RIGHT JOIN martech_archive_site bb ON aa.site_id = bb.site_id\n",
    "GROUP BY bb.year, bb.month, bb.day, bb.site_id\n",
    "\"\"\"\n",
    "\n",
    "df_tech_cell_cnt = spark.sql(dynamic_tech_cell_cnt_sql)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7ca7eb84-b880-46eb-81ff-aff723a3a741",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Generate a dynamic sql to get the final frequency result\n",
    "\n",
    "dynamic_frequency_band = [row[0] for row in df_tech_dimension.select('frequency_band_value').distinct().collect()]\n",
    "\n",
    "# Generate MAX(COALESCE(...)) clauses for the SELECT statement\n",
    "max_coalesce_clauses = \",\\n       \".join([f\"MAX(COALESCE({col}, 0)) AS {col}\" for col in dynamic_frequency_band])\n",
    "\n",
    "# Generate PIVOT clause values\n",
    "pivot_values = \", \".join([f\"'{col}'\" for col in dynamic_frequency_band])\n",
    "\n",
    "dynamic_frequency_band_sql = f\"\"\"\n",
    "-- frequency_band \n",
    "SELECT bb.year, bb.month, bb.day, bb.site_id,\n",
    "       -- frequency_band\n",
    "       {max_coalesce_clauses}\n",
    "FROM (\n",
    "  SELECT *\n",
    "    FROM (\n",
    "        SELECT year, month, day, tech_type, site_id, frequency_band\n",
    "        FROM martech_archive_data\n",
    "    )  a \n",
    "    JOIN (\n",
    "        SELECT tech_type, frequency, frequency_band_value\n",
    "          FROM dim_tech_info\n",
    "        GROUP BY tech_type, frequency, frequency_band_value\n",
    "    )  b ON a.tech_type = b.tech_type AND a.frequency_band = b.frequency\n",
    "    PIVOT (\n",
    "      MAX(IF(frequency_band IS NOT NULL, 1, 0)) AS frenquency_is_exist\n",
    "      FOR frequency_band_value IN ({pivot_values}) \n",
    "    )\n",
    ") aa RIGHT JOIN martech_archive_site bb ON aa.site_id = bb.site_id\n",
    "GROUP BY bb.year, bb.month, bb.day, bb.site_id\n",
    "\"\"\"\n",
    "\n",
    "df_frequency_band_cnt =spark.sql(dynamic_frequency_band_sql)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "27adc8a9-a50f-4faf-917a-d1c84a716203",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# full join the two dataframes, then sink the data into google cloud storage\n",
    "join_conditions = [\"year\", \"month\", \"day\", \"site_id\"]\n",
    "result_df = df_tech_cell_cnt.join(df_frequency_band_cnt, join_conditions, \"fullouter\")\n",
    "\n",
    "gcs_output_path = \"gs://martech-archive-data/Result/year={year}/month={mon}/day={day}/result.csv\".format(year=year, mon=month, day=day)\n",
    "\n",
    "result_df.write.format('csv').mode('overwrite').option(\"header\", True).save(gcs_output_path)"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 5530975304580913,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "Martech-Assignment-V2-Prod",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
